{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j32hazFU4h8",
        "outputId": "d64cf763-0ac7-43b6-8454-d8ac43c2a451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating sample data...\n",
            "Preprocessing data...\n",
            "Engineering features...\n",
            "Creating sequences...\n",
            "Building and training LSTM model...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 3.9750 - mae: 1.5971"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 356ms/step - loss: 3.6161 - mae: 1.5262 - val_loss: 0.5535 - val_mae: 0.7243\n",
            "Epoch 2/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.9094 - mae: 1.3233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.7107 - mae: 1.2714 - val_loss: 0.4808 - val_mae: 0.6723\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.2907 - mae: 1.3054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2.3087 - mae: 1.3076 - val_loss: 0.4161 - val_mae: 0.6223\n",
            "Epoch 4/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.0111 - mae: 1.1492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.0418 - mae: 1.1784 - val_loss: 0.3548 - val_mae: 0.5710\n",
            "Epoch 5/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.7215 - mae: 1.0693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.8271 - mae: 1.1036 - val_loss: 0.3145 - val_mae: 0.5346\n",
            "Epoch 6/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.6188 - mae: 0.9459"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.6546 - mae: 0.9745 - val_loss: 0.2735 - val_mae: 0.4947\n",
            "Epoch 7/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.8060 - mae: 1.0626"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.6108 - mae: 1.0150 - val_loss: 0.2494 - val_mae: 0.4700\n",
            "Epoch 8/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.9604 - mae: 0.7631"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.2099 - mae: 0.8516 - val_loss: 0.2207 - val_mae: 0.4384\n",
            "Epoch 9/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.7435 - mae: 1.0487"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.4321 - mae: 0.9514 - val_loss: 0.2029 - val_mae: 0.4178\n",
            "Epoch 10/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.9219 - mae: 0.7824"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.1162 - mae: 0.8247 - val_loss: 0.1726 - val_mae: 0.3802\n",
            "Epoch 11/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.6998 - mae: 0.6578"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8753 - mae: 0.7450 - val_loss: 0.1404 - val_mae: 0.3353\n",
            "Epoch 12/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.7359 - mae: 0.6271"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7665 - mae: 0.6675 - val_loss: 0.1154 - val_mae: 0.2969\n",
            "Epoch 13/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.0091 - mae: 0.8582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.8026 - mae: 0.7443 - val_loss: 0.1138 - val_mae: 0.2943\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.7795 - mae: 0.6617 - val_loss: 0.1242 - val_mae: 0.3109\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8809 - mae: 0.7309 - val_loss: 0.1281 - val_mae: 0.3169\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5117 - mae: 0.5690 - val_loss: 0.1286 - val_mae: 0.3180\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6801 - mae: 0.6607 - val_loss: 0.1213 - val_mae: 0.3075\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7565 - mae: 0.6997 - val_loss: 0.1169 - val_mae: 0.3003\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3977 - mae: 0.5143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.4205 - mae: 0.5277 - val_loss: 0.1089 - val_mae: 0.2873\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5406 - mae: 0.5969 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.5464 - mae: 0.6013 - val_loss: 0.0973 - val_mae: 0.2662\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5672 - mae: 0.5855 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.5576 - mae: 0.5799 - val_loss: 0.0952 - val_mae: 0.2609\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5886 - mae: 0.5751 - val_loss: 0.0985 - val_mae: 0.2650\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4221 - mae: 0.5097 - val_loss: 0.1109 - val_mae: 0.2841\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4042 - mae: 0.4857 - val_loss: 0.1219 - val_mae: 0.3020\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3991 - mae: 0.5115 - val_loss: 0.1231 - val_mae: 0.3041\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3756 - mae: 0.4692 - val_loss: 0.1160 - val_mae: 0.2931\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3647 - mae: 0.5007 - val_loss: 0.1051 - val_mae: 0.2732\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3226 - mae: 0.4571 - val_loss: 0.0971 - val_mae: 0.2608\n",
            "Epoch 29/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1822 - mae: 0.3638"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.2977 - mae: 0.4402 - val_loss: 0.0914 - val_mae: 0.2519\n",
            "Epoch 30/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3751 - mae: 0.4773"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3897 - mae: 0.4797 - val_loss: 0.0870 - val_mae: 0.2450\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4651 - mae: 0.5463 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.4615 - mae: 0.5439 - val_loss: 0.0856 - val_mae: 0.2434\n",
            "Epoch 32/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3826 - mae: 0.5252"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3890 - mae: 0.5128 - val_loss: 0.0818 - val_mae: 0.2361\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3531 - mae: 0.4794"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3499 - mae: 0.4789 - val_loss: 0.0713 - val_mae: 0.2174\n",
            "Epoch 34/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3901 - mae: 0.4348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3184 - mae: 0.4127 - val_loss: 0.0648 - val_mae: 0.2077\n",
            "Epoch 35/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.3323 - mae: 0.4358"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3023 - mae: 0.4206 - val_loss: 0.0601 - val_mae: 0.2013\n",
            "Epoch 36/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2664 - mae: 0.3908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3013 - mae: 0.4074 - val_loss: 0.0563 - val_mae: 0.1959\n",
            "Epoch 37/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.1909 - mae: 0.3300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2316 - mae: 0.3749 - val_loss: 0.0536 - val_mae: 0.1915\n",
            "Epoch 38/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3069 - mae: 0.4302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2766 - mae: 0.4067 - val_loss: 0.0511 - val_mae: 0.1876\n",
            "Epoch 39/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.3001 - mae: 0.4608"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2686 - mae: 0.4241 - val_loss: 0.0500 - val_mae: 0.1855\n",
            "Epoch 40/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.2582 - mae: 0.4335"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2718 - mae: 0.4411 - val_loss: 0.0494 - val_mae: 0.1843\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3092 - mae: 0.4497 - val_loss: 0.0502 - val_mae: 0.1856\n",
            "Epoch 42/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2484 - mae: 0.4092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2414 - mae: 0.3953 - val_loss: 0.0490 - val_mae: 0.1832\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2055 - mae: 0.3688 - val_loss: 0.0521 - val_mae: 0.1906\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3059 - mae: 0.4370 - val_loss: 0.0561 - val_mae: 0.1996\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2317 - mae: 0.3892 - val_loss: 0.0543 - val_mae: 0.1969\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1855 - mae: 0.3428 - val_loss: 0.0513 - val_mae: 0.1910\n",
            "Epoch 47/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1615 - mae: 0.3212"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1481 - mae: 0.3081 - val_loss: 0.0483 - val_mae: 0.1862\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1818 - mae: 0.3703 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1854 - mae: 0.3734 - val_loss: 0.0461 - val_mae: 0.1822\n",
            "Epoch 49/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1597 - mae: 0.3490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1806 - mae: 0.3616 - val_loss: 0.0436 - val_mae: 0.1701\n",
            "Epoch 50/50\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1907 - mae: 0.3565"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1757 - mae: 0.3382 - val_loss: 0.0432 - val_mae: 0.1644\n",
            "Selecting features...\n",
            "Building and training RF model...\n",
            "Evaluating models...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
            "Evaluation results: {'rf_accuracy': 0.9705882352941176, 'rf_f1': 0.9561018437225637, 'rf_confusion_matrix': array([[ 0,  1],\n",
            "       [ 0, 33]]), 'lstm_mae': 0.19660922690304056, 'lstm_rmse': np.float64(0.2621820594087152), 'lstm_r2': np.float64(-0.6283793307966079)}\n",
            "Preparing model for deployment...\n",
            "Saved artifact at '/tmp/tmpdbjlkgoh'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 24, 20), dtype=tf.float32, name='keras_tensor_54')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134299027838672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299027836368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299027839440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063832592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063838736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299027837136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299027836560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063830480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063830672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063831056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063831440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063833360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063829904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063832784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299063829520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299056749072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299056741008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134299056750224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model saved as pet_activity_model.tflite\n",
            "Complete! The model is ready for integration with the Marshee app and device.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
        "from sklearn.feature_selection import RFE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "class PetActivityAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_scaler = MinMaxScaler()\n",
        "        self.lstm_model = None\n",
        "        self.rf_model = None\n",
        "        self.selected_features = None\n",
        "        self.sequence_length = 24  # Default 24 time steps (e.g., 24 seconds)\n",
        "\n",
        "    def preprocess_data(self, raw_data):\n",
        "        \"\"\"\n",
        "        Preprocess raw sensor data from the Marshee device\n",
        "\n",
        "        Parameters:\n",
        "        raw_data (DataFrame): Raw accelerometer and gyroscope data\n",
        "                             Expected columns: timestamp, acc_x, acc_y, acc_z, gyro_x, gyro_y, gyro_z\n",
        "\n",
        "        Returns:\n",
        "        DataFrame: Preprocessed data with engineered features\n",
        "        \"\"\"\n",
        "        # Create a copy to avoid modifying the original\n",
        "        data = raw_data.copy()\n",
        "\n",
        "        # Ensure data is sorted by timestamp\n",
        "        data = data.sort_values('timestamp')\n",
        "\n",
        "        # Calculate magnitude of acceleration\n",
        "        data['acc_magnitude'] = np.sqrt(data['acc_x']**2 + data['acc_y']**2 + data['acc_z']**2)\n",
        "\n",
        "        # Calculate magnitude of angular velocity\n",
        "        data['gyro_magnitude'] = np.sqrt(data['gyro_x']**2 + data['gyro_y']**2 + data['gyro_z']**2)\n",
        "\n",
        "        # Apply moving average filter to reduce noise (window size of 5)\n",
        "        data['acc_magnitude_smooth'] = data['acc_magnitude'].rolling(window=5, center=True).mean()\n",
        "        data['gyro_magnitude_smooth'] = data['gyro_magnitude'].rolling(window=5, center=True).mean()\n",
        "\n",
        "        # Fill NaN values created by rolling window\n",
        "        data = data.bfill().ffill()\n",
        "\n",
        "        # Calculate step frequency (time derivative of acceleration)\n",
        "        data['acc_derivative'] = data['acc_magnitude_smooth'].diff() / data['timestamp'].diff().dt.total_seconds()\n",
        "\n",
        "        # Calculate jerk (derivative of acceleration)\n",
        "        data['jerk'] = data['acc_derivative'].diff() / data['timestamp'].diff().dt.total_seconds()\n",
        "\n",
        "        # Calculate activity burst indicator (high acceleration periods)\n",
        "        data['activity_burst'] = (data['acc_magnitude_smooth'] > data['acc_magnitude_smooth'].mean() +\n",
        "                                 data['acc_magnitude_smooth'].std()).astype(int)\n",
        "\n",
        "        # Feature: Rest periods (low activity periods)\n",
        "        data['rest_period'] = (data['acc_magnitude_smooth'] < data['acc_magnitude_smooth'].mean() -\n",
        "                              0.5 * data['acc_magnitude_smooth'].std()).astype(int)\n",
        "\n",
        "        # Calculate rest duration (cumulative sum of consecutive rest periods)\n",
        "        data['rest_group'] = (data['rest_period'].diff() != 0).cumsum()\n",
        "        rest_durations = data[data['rest_period'] == 1].groupby('rest_group')['timestamp'].agg(['count']).reset_index()\n",
        "\n",
        "        # Merge rest durations back\n",
        "        data = data.merge(rest_durations, on='rest_group', how='left')\n",
        "        data['rest_duration'] = data['count'].fillna(0)\n",
        "        data = data.drop(['count', 'rest_group'], axis=1)\n",
        "\n",
        "        # Generate time-based features\n",
        "        data['hour_of_day'] = data['timestamp'].dt.hour\n",
        "        data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "\n",
        "        # Calculate hour-based activity patterns\n",
        "        hourly_activity = data.groupby('hour_of_day')['acc_magnitude_smooth'].mean().reset_index()\n",
        "        data = data.merge(hourly_activity, on='hour_of_day', suffixes=('', '_hourly_avg'))\n",
        "\n",
        "        # Calculate activity intensity (normalized acceleration magnitude)\n",
        "        data['activity_intensity'] = data['acc_magnitude_smooth'] / data['acc_magnitude_smooth'].max()\n",
        "\n",
        "        # Calculate activity regularity (std dev of acceleration in rolling windows)\n",
        "        data['activity_regularity'] = data['acc_magnitude_smooth'].rolling(window=20).std()\n",
        "        data['activity_regularity'] = data['activity_regularity'].bfill().ffill()\n",
        "\n",
        "        return data\n",
        "\n",
        "    def engineer_features(self, preprocessed_data, window_size=60):\n",
        "        \"\"\"\n",
        "        Engineer features from preprocessed data using sliding windows\n",
        "\n",
        "        Parameters:\n",
        "        preprocessed_data (DataFrame): Output from preprocess_data\n",
        "        window_size (int): Size of sliding window in seconds\n",
        "\n",
        "        Returns:\n",
        "        DataFrame: Feature-engineered data ready for model training\n",
        "        \"\"\"\n",
        "        # Create a copy to avoid modifying the original\n",
        "        data = preprocessed_data.copy()\n",
        "\n",
        "        # Create time windows (assuming data is in seconds)\n",
        "        data['time_window'] = (data['timestamp'] - data['timestamp'].min()).dt.total_seconds() // window_size\n",
        "\n",
        "        # Aggregate features by time window\n",
        "        features = data.groupby('time_window').agg({\n",
        "            'acc_magnitude_smooth': ['mean', 'std', 'max', 'min'],\n",
        "            'gyro_magnitude_smooth': ['mean', 'std', 'max'],\n",
        "            'activity_burst': 'sum',\n",
        "            'rest_period': 'sum',\n",
        "            'rest_duration': 'max',\n",
        "            'activity_intensity': ['mean', 'max'],\n",
        "            'activity_regularity': 'mean',\n",
        "            'acc_derivative': ['mean', 'std'],\n",
        "            'jerk': ['mean', 'std', 'max']\n",
        "        })\n",
        "\n",
        "        # Flatten multi-index columns\n",
        "        features.columns = ['_'.join(col).strip() for col in features.columns.values]\n",
        "\n",
        "        # Calculate additional window-level features\n",
        "\n",
        "        # Activity ratio (percentage of window spent active)\n",
        "        features['activity_ratio'] = 1 - (features['rest_period_sum'] / window_size)\n",
        "\n",
        "        # Activity variability (ratio of std to mean of acceleration)\n",
        "        features['activity_variability'] = features['acc_magnitude_smooth_std'] / features['acc_magnitude_smooth_mean']\n",
        "\n",
        "        # Replace infinity and NaN values\n",
        "        features = features.replace([np.inf, -np.inf], np.nan)\n",
        "        features = features.fillna(0)\n",
        "\n",
        "        # Normalize features\n",
        "        normalized_features = self.feature_scaler.fit_transform(features)\n",
        "        normalized_features_df = pd.DataFrame(normalized_features, columns=features.columns)\n",
        "\n",
        "        # Add time information back\n",
        "        normalized_features_df['time_window'] = features.index\n",
        "\n",
        "        return normalized_features_df\n",
        "\n",
        "    def create_sequences(self, feature_data, sequence_length=None):\n",
        "        \"\"\"\n",
        "        Create sequences for LSTM model\n",
        "\n",
        "        Parameters:\n",
        "        feature_data (DataFrame): Output from engineer_features\n",
        "        sequence_length (int): Length of sequences to create\n",
        "\n",
        "        Returns:\n",
        "        tuple: (X, y) where X is sequence data and y is labels\n",
        "        \"\"\"\n",
        "        if sequence_length is None:\n",
        "            sequence_length = self.sequence_length\n",
        "        else:\n",
        "            self.sequence_length = sequence_length\n",
        "\n",
        "        # Drop time_window from features for sequence creation\n",
        "        features = feature_data.drop('time_window', axis=1).values\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(len(features) - sequence_length):\n",
        "            X.append(features[i:i + sequence_length])\n",
        "\n",
        "            # For this example, we'll predict activity level (can be modified based on specific goals)\n",
        "            # Using mean activity intensity of next time window as target\n",
        "            target_idx = min(i + sequence_length, len(features) - 1)\n",
        "            activity_idx = list(feature_data.columns).index('activity_intensity_mean')\n",
        "            y.append(features[target_idx][activity_idx])\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def feature_selection(self, feature_data, target_col='activity_intensity_mean', n_features=10):\n",
        "        \"\"\"\n",
        "        Perform feature selection using Random Forest importance\n",
        "\n",
        "        Parameters:\n",
        "        feature_data (DataFrame): Feature engineered data\n",
        "        target_col (str): Target column name\n",
        "        n_features (int): Number of features to select\n",
        "\n",
        "        Returns:\n",
        "        list: Selected feature names\n",
        "        \"\"\"\n",
        "        # Prepare data\n",
        "        X = feature_data.drop(['time_window', target_col], axis=1)\n",
        "        y = feature_data[target_col]\n",
        "\n",
        "        # Initialize RF for feature importance - use RandomForestRegressor instead of Classifier\n",
        "        rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "        # Use RFE for feature selection\n",
        "        rfe = RFE(estimator=rf, n_features_to_select=n_features)\n",
        "        rfe.fit(X, y)\n",
        "\n",
        "        # Get selected features\n",
        "        selected_features = X.columns[rfe.support_].tolist()\n",
        "        self.selected_features = selected_features\n",
        "\n",
        "        return selected_features\n",
        "\n",
        "    def build_lstm_model(self, input_shape, output_size=1):\n",
        "        \"\"\"\n",
        "        Build LSTM model for time series prediction\n",
        "\n",
        "        Parameters:\n",
        "        input_shape (tuple): Shape of input data (sequence_length, n_features)\n",
        "        output_size (int): Number of output nodes\n",
        "\n",
        "        Returns:\n",
        "        Model: Compiled Keras LSTM model\n",
        "        \"\"\"\n",
        "        model = Sequential([\n",
        "            LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "            Dropout(0.2),\n",
        "            BatchNormalization(),\n",
        "            LSTM(32),\n",
        "            Dropout(0.2),\n",
        "            BatchNormalization(),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dense(output_size, activation='linear')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='mean_squared_error',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "\n",
        "        self.lstm_model = model\n",
        "        return model\n",
        "\n",
        "    def train_lstm_model(self, X, y, epochs=100, batch_size=32, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the LSTM model\n",
        "\n",
        "        Parameters:\n",
        "        X (numpy.array): Sequence data\n",
        "        y (numpy.array): Target values\n",
        "        epochs (int): Number of training epochs\n",
        "        batch_size (int): Batch size for training\n",
        "        validation_split (float): Portion of data to use for validation\n",
        "\n",
        "        Returns:\n",
        "        History: Training history\n",
        "        \"\"\"\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        checkpoint = ModelCheckpoint(\n",
        "            'best_pet_activity_model.h5',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True\n",
        "        )\n",
        "\n",
        "        history = self.lstm_model.fit(\n",
        "            X, y,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=[early_stopping, checkpoint],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def build_rf_model(self):\n",
        "        \"\"\"\n",
        "        Build Random Forest model for activity classification\n",
        "\n",
        "        Returns:\n",
        "        RandomForestClassifier: Initialized RF model\n",
        "        \"\"\"\n",
        "        rf_model = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.rf_model = rf_model\n",
        "        return rf_model\n",
        "\n",
        "    def train_rf_model(self, X, y):\n",
        "        \"\"\"\n",
        "        Train Random Forest model\n",
        "\n",
        "        Parameters:\n",
        "        X (numpy.array): Feature data\n",
        "        y (numpy.array): Target labels\n",
        "\n",
        "        Returns:\n",
        "        RandomForestClassifier: Trained RF model\n",
        "        \"\"\"\n",
        "        self.rf_model.fit(X, y)\n",
        "        return self.rf_model\n",
        "\n",
        "    def prepare_for_deployment(self, quantize=True):\n",
        "        \"\"\"\n",
        "        Prepare model for deployment to device\n",
        "\n",
        "        Parameters:\n",
        "        quantize (bool): Whether to quantize the model\n",
        "\n",
        "        Returns:\n",
        "        bytes: TFLite model ready for deployment\n",
        "        \"\"\"\n",
        "        converter = tf.lite.TFLiteConverter.from_keras_model(self.lstm_model)\n",
        "\n",
        "        # Add these experimental flags for TensorList handling\n",
        "        converter.experimental_enable_resource_variables = True\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "        converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "        if quantize:\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "            converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "        try:\n",
        "            tflite_model = converter.convert()\n",
        "        except Exception as e:\n",
        "            print(f\"Conversion error: {e}\")\n",
        "            raise\n",
        "\n",
        "        return tflite_model\n",
        "\n",
        "    def evaluate_models(self, X_test, y_test, X_test_seq=None, y_test_seq=None):\n",
        "        \"\"\"\n",
        "        Evaluate models on test data\n",
        "\n",
        "        Parameters:\n",
        "        X_test (numpy.array): Test features for RF model\n",
        "        y_test (numpy.array): Test labels for RF model\n",
        "        X_test_seq (numpy.array): Test sequence data for LSTM model\n",
        "        y_test_seq (numpy.array): Test targets for LSTM model\n",
        "\n",
        "        Returns:\n",
        "        dict: Dictionary of evaluation metrics\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Evaluate RF model\n",
        "        if self.rf_model is not None and X_test is not None and y_test is not None:\n",
        "            y_pred = self.rf_model.predict(X_test)\n",
        "            results['rf_accuracy'] = accuracy_score(y_test, y_pred)\n",
        "            results['rf_f1'] = f1_score(y_test, y_pred, average='weighted')\n",
        "            results['rf_confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Evaluate LSTM model\n",
        "        if self.lstm_model is not None and X_test_seq is not None and y_test_seq is not None:\n",
        "            lstm_preds = self.lstm_model.predict(X_test_seq)\n",
        "            results['lstm_mae'] = mean_absolute_error(y_test_seq, lstm_preds)\n",
        "\n",
        "            # Calculate RMSE\n",
        "            results['lstm_rmse'] = np.sqrt(np.mean((y_test_seq - lstm_preds.flatten())**2))\n",
        "\n",
        "            # Calculate R-squared\n",
        "            ss_total = np.sum((y_test_seq - np.mean(y_test_seq))**2)\n",
        "            ss_residual = np.sum((y_test_seq - lstm_preds.flatten())**2)\n",
        "            results['lstm_r2'] = 1 - (ss_residual / ss_total)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def classify_activity(self, feature_window):\n",
        "        \"\"\"\n",
        "        Classify activity type from a window of features\n",
        "\n",
        "        Parameters:\n",
        "        feature_window (numpy.array): Window of features\n",
        "\n",
        "        Returns:\n",
        "        str: Activity classification\n",
        "        float: Confidence score\n",
        "        \"\"\"\n",
        "        if self.rf_model is None:\n",
        "            raise ValueError(\"Random Forest model not trained. Call train_rf_model first.\")\n",
        "\n",
        "        # Ensure feature window is properly shaped and contains only selected features\n",
        "        if self.selected_features is not None:\n",
        "            # Extract only selected features if they exist in the input\n",
        "            feature_cols = self.selected_features\n",
        "        else:\n",
        "            feature_cols = feature_window.columns\n",
        "\n",
        "        # Get prediction\n",
        "        prediction_prob = self.rf_model.predict_proba(feature_window[feature_cols].values.reshape(1, -1))\n",
        "        prediction = self.rf_model.predict(feature_window[feature_cols].values.reshape(1, -1))\n",
        "\n",
        "        # Map prediction to activity label\n",
        "        activity_labels = ['rest', 'walking', 'running', 'playing']\n",
        "        activity_type = activity_labels[prediction[0]] if prediction[0] < len(activity_labels) else 'unknown'\n",
        "\n",
        "        # Get confidence\n",
        "        confidence = np.max(prediction_prob)\n",
        "\n",
        "        return activity_type, confidence\n",
        "\n",
        "    def predict_future_activity(self, current_sequence):\n",
        "        \"\"\"\n",
        "        Predict future activity level based on current sequence\n",
        "\n",
        "        Parameters:\n",
        "        current_sequence (numpy.array): Current sequence of features\n",
        "\n",
        "        Returns:\n",
        "        float: Predicted activity level\n",
        "        \"\"\"\n",
        "        if self.lstm_model is None:\n",
        "            raise ValueError(\"LSTM model not trained. Call train_lstm_model first.\")\n",
        "\n",
        "        # Ensure proper shape\n",
        "        if len(current_sequence.shape) == 2:\n",
        "            # Add batch dimension if needed\n",
        "            current_sequence = np.expand_dims(current_sequence, axis=0)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.lstm_model.predict(current_sequence)\n",
        "\n",
        "        return prediction[0][0]\n",
        "\n",
        "    def detect_anomalies(self, feature_window, threshold=2.0):\n",
        "        \"\"\"\n",
        "        Detect anomalies in activity patterns\n",
        "\n",
        "        Parameters:\n",
        "        feature_window (numpy.array): Window of features\n",
        "        threshold (float): Threshold for anomaly detection (standard deviations)\n",
        "\n",
        "        Returns:\n",
        "        bool: True if anomaly detected, False otherwise\n",
        "        dict: Anomaly details\n",
        "        \"\"\"\n",
        "        # Get predictions\n",
        "        activity_level = self.predict_future_activity(feature_window)\n",
        "\n",
        "        # Compare with expected range\n",
        "        expected_range = self.activity_baseline_stats.get('mean', 0.5) + threshold * self.activity_baseline_stats.get('std', 0.2)\n",
        "\n",
        "        is_anomaly = abs(activity_level - self.activity_baseline_stats.get('mean', 0.5)) > expected_range\n",
        "\n",
        "        details = {\n",
        "            'predicted_activity': activity_level,\n",
        "            'baseline_mean': self.activity_baseline_stats.get('mean', 0.5),\n",
        "            'threshold': expected_range,\n",
        "            'deviation': abs(activity_level - self.activity_baseline_stats.get('mean', 0.5))\n",
        "        }\n",
        "\n",
        "        return is_anomaly, details\n",
        "\n",
        "    def set_activity_baseline(self, activity_data):\n",
        "        \"\"\"\n",
        "        Set baseline statistics for anomaly detection\n",
        "\n",
        "        Parameters:\n",
        "        activity_data (numpy.array): Historical activity data\n",
        "\n",
        "        Returns:\n",
        "        dict: Baseline statistics\n",
        "        \"\"\"\n",
        "        self.activity_baseline_stats = {\n",
        "            'mean': np.mean(activity_data),\n",
        "            'std': np.std(activity_data),\n",
        "            'min': np.min(activity_data),\n",
        "            'max': np.max(activity_data)\n",
        "        }\n",
        "\n",
        "        return self.activity_baseline_stats\n",
        "\n",
        "    def visualize_activity_patterns(self, activity_data, timestamps):\n",
        "        \"\"\"\n",
        "        Visualize activity patterns over time\n",
        "\n",
        "        Parameters:\n",
        "        activity_data (numpy.array): Activity intensity data\n",
        "        timestamps (numpy.array): Corresponding timestamps\n",
        "\n",
        "        Returns:\n",
        "        matplotlib.figure.Figure: Figure object with visualization\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "        # Plot activity intensity over time\n",
        "        axes[0].plot(timestamps, activity_data, 'b-', label='Activity Intensity')\n",
        "        axes[0].set_title('Pet Activity Patterns')\n",
        "        axes[0].set_ylabel('Activity Intensity')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Plot hourly patterns (boxplot)\n",
        "        hourly_data = pd.DataFrame({'hour': pd.to_datetime(timestamps).hour, 'activity': activity_data})\n",
        "        sns.boxplot(x='hour', y='activity', data=hourly_data, ax=axes[1])\n",
        "        axes[1].set_title('Hourly Activity Distribution')\n",
        "        axes[1].set_xlabel('Hour of Day')\n",
        "        axes[1].set_ylabel('Activity Intensity')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "# Main execution for demonstration\n",
        "def generate_sample_data(num_samples=1000):\n",
        "    \"\"\"Generate sample accelerometer and gyroscope data for demonstration\"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Create timestamps (one sample per second)\n",
        "    start_time = pd.Timestamp('2023-01-01 08:00:00')\n",
        "    timestamps = [start_time + pd.Timedelta(seconds=i) for i in range(num_samples)]\n",
        "\n",
        "    # Create synthetic patterns (rest, walking, playing)\n",
        "    patterns = np.random.choice(['rest', 'walking', 'playing'], size=num_samples, p=[0.3, 0.5, 0.2])\n",
        "\n",
        "    # Generate accelerometer data based on patterns\n",
        "    acc_x = np.zeros(num_samples)\n",
        "    acc_y = np.zeros(num_samples)\n",
        "    acc_z = np.zeros(num_samples)\n",
        "\n",
        "    # Rest pattern (low activity)\n",
        "    rest_idx = np.where(patterns == 'rest')[0]\n",
        "    acc_x[rest_idx] = np.random.normal(0, 0.1, size=len(rest_idx))\n",
        "    acc_y[rest_idx] = np.random.normal(0, 0.1, size=len(rest_idx))\n",
        "    acc_z[rest_idx] = np.random.normal(1, 0.1, size=len(rest_idx))  # Gravity\n",
        "\n",
        "    # Walking pattern (moderate activity)\n",
        "    walk_idx = np.where(patterns == 'walking')[0]\n",
        "    acc_x[walk_idx] = np.random.normal(0, 0.3, size=len(walk_idx))\n",
        "    acc_y[walk_idx] = np.random.normal(0, 0.3, size=len(walk_idx))\n",
        "    acc_z[walk_idx] = np.random.normal(1, 0.3, size=len(walk_idx))\n",
        "\n",
        "    # Playing pattern (high activity)\n",
        "    play_idx = np.where(patterns == 'playing')[0]\n",
        "    acc_x[play_idx] = np.random.normal(0, 0.8, size=len(play_idx))\n",
        "    acc_y[play_idx] = np.random.normal(0, 0.8, size=len(play_idx))\n",
        "    acc_z[play_idx] = np.random.normal(1, 0.8, size=len(play_idx))\n",
        "\n",
        "    # Generate gyroscope data\n",
        "    gyro_x = np.zeros(num_samples)\n",
        "    gyro_y = np.zeros(num_samples)\n",
        "    gyro_z = np.zeros(num_samples)\n",
        "\n",
        "    gyro_x[rest_idx] = np.random.normal(0, 0.05, size=len(rest_idx))\n",
        "    gyro_y[rest_idx] = np.random.normal(0, 0.05, size=len(rest_idx))\n",
        "    gyro_z[rest_idx] = np.random.normal(0, 0.05, size=len(rest_idx))\n",
        "\n",
        "    gyro_x[walk_idx] = np.random.normal(0, 0.2, size=len(walk_idx))\n",
        "    gyro_y[walk_idx] = np.random.normal(0, 0.2, size=len(walk_idx))\n",
        "    gyro_z[walk_idx] = np.random.normal(0, 0.2, size=len(walk_idx))\n",
        "\n",
        "    gyro_x[play_idx] = np.random.normal(0, 0.6, size=len(play_idx))\n",
        "    gyro_y[play_idx] = np.random.normal(0, 0.6, size=len(play_idx))\n",
        "    gyro_z[play_idx] = np.random.normal(0, 0.6, size=len(play_idx))\n",
        "\n",
        "    # Create DataFrame\n",
        "    data = pd.DataFrame({\n",
        "        'timestamp': timestamps,\n",
        "        'acc_x': acc_x,\n",
        "        'acc_y': acc_y,\n",
        "        'acc_z': acc_z,\n",
        "        'gyro_x': gyro_x,\n",
        "        'gyro_y': gyro_y,\n",
        "        'gyro_z': gyro_z,\n",
        "        'activity_type': patterns  # Ground truth for evaluation\n",
        "    })\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate sample data\n",
        "    print(\"Generating sample data...\")\n",
        "    sample_data = generate_sample_data(10000)\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = PetActivityAnalyzer()\n",
        "\n",
        "    # Preprocess data\n",
        "    print(\"Preprocessing data...\")\n",
        "    preprocessed_data = analyzer.preprocess_data(sample_data)\n",
        "\n",
        "    # Add time_window to preprocessed_data using the same window_size as engineer_features\n",
        "    window_size = 60  # Must match what's used in engineer_features()\n",
        "    preprocessed_data['time_window'] = (\n",
        "        (preprocessed_data['timestamp'] - preprocessed_data['timestamp'].min()).dt.total_seconds() // window_size\n",
        "    )\n",
        "\n",
        "    # Engineer features\n",
        "    print(\"Engineering features...\")\n",
        "    feature_data = analyzer.engineer_features(preprocessed_data)\n",
        "\n",
        "    # Create sequences for LSTM\n",
        "    print(\"Creating sequences...\")\n",
        "    X_seq, y_seq = analyzer.create_sequences(feature_data)\n",
        "\n",
        "    # Train/test split for sequences\n",
        "    X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n",
        "        X_seq, y_seq, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Build and train LSTM model\n",
        "    print(\"Building and training LSTM model...\")\n",
        "    input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
        "    analyzer.build_lstm_model(input_shape)\n",
        "    history = analyzer.train_lstm_model(X_train_seq, y_train_seq, epochs=50)\n",
        "\n",
        "    # Select features and prepare for RF model\n",
        "    print(\"Selecting features...\")\n",
        "    selected_features = analyzer.feature_selection(feature_data)\n",
        "\n",
        "    # Extract activity types for classification\n",
        "    activity_mapping = {'rest': 0, 'walking': 1, 'playing': 2}\n",
        "    feature_data['activity_label'] = preprocessed_data.groupby('time_window')['activity_type'].agg(\n",
        "        lambda x: activity_mapping.get(x.mode()[0], 0)  # Handle cases with no clear mode\n",
        "    ).values\n",
        "\n",
        "    # Prepare data for RF\n",
        "    X_rf = feature_data[selected_features]\n",
        "    y_rf = feature_data['activity_label']\n",
        "\n",
        "    # Train/test split for RF\n",
        "    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "        X_rf, y_rf, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Build and train RF model\n",
        "    print(\"Building and training RF model...\")\n",
        "    analyzer.build_rf_model()\n",
        "    analyzer.train_rf_model(X_train_rf, y_train_rf)\n",
        "\n",
        "    # Evaluate models\n",
        "    print(\"Evaluating models...\")\n",
        "    results = analyzer.evaluate_models(X_test_rf, y_test_rf, X_test_seq, y_test_seq)\n",
        "    print(\"Evaluation results:\", results)\n",
        "\n",
        "    # Prepare for deployment\n",
        "    print(\"Preparing model for deployment...\")\n",
        "    tflite_model = analyzer.prepare_for_deployment()\n",
        "\n",
        "    # Save TFLite model\n",
        "    with open('pet_activity_model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"Model saved as pet_activity_model.tflite\")\n",
        "\n",
        "    # Set activity baseline for anomaly detection\n",
        "    analyzer.set_activity_baseline(y_seq)\n",
        "\n",
        "    print(\"Complete! The model is ready for integration with the Marshee app and device.\")"
      ]
    }
  ]
}